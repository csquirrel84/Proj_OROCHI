#!/usr/bin/env ansible-playbook
---
- name: Deploy Orochi Security Stack
  hosts: orochi_servers
  become: true
  gather_facts: true

  tasks:
    # ============================================
    # Docker Installation
    # ============================================
    - name: Check if Docker is installed
      ansible.builtin.command: docker --version
      register: docker_installed
      ignore_errors: true
      changed_when: false

    - name: Display current Docker status
      ansible.builtin.debug:
        msg: "{{ 'Docker already installed: ' + docker_installed.stdout if docker_installed.rc == 0 else 'Docker not found - will install' }}"

    - name: Install Docker on Debian/Ubuntu
      when: 
        - docker_installed.rc != 0
        - ansible_os_family == "Debian"
      block:
        - name: Install required packages
          ansible.builtin.apt:
            name:
              - apt-transport-https
              - ca-certificates
              - curl
              - gnupg
              - lsb-release
            state: present
            update_cache: true

        - name: Create keyrings directory
          ansible.builtin.file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Docker GPG key
          ansible.builtin.get_url:
            url: https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg
            dest: /etc/apt/keyrings/docker.asc
            mode: '0644'

        - name: Add Docker repository
          ansible.builtin.apt_repository:
            repo: "deb [arch={{ ansible_architecture | replace('x86_64', 'amd64') }} signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
            state: present
            filename: docker

        - name: Install Docker packages
          ansible.builtin.apt:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: latest
            update_cache: true

    - name: Install Docker on RHEL/CentOS/Fedora
      when: 
        - docker_installed.rc != 0
        - ansible_os_family == "RedHat"
      block:
        - name: Install required packages
          ansible.builtin.yum:
            name:
              - yum-utils
            state: present

        - name: Add Docker repository
          ansible.builtin.yum_repository:
            name: docker-ce
            description: Docker CE Stable
            baseurl: https://download.docker.com/linux/centos/$releasever/$basearch/stable
            gpgcheck: true
            gpgkey: https://download.docker.com/linux/centos/gpg
            enabled: true

        - name: Install Docker packages
          ansible.builtin.yum:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: latest

    - name: Start and enable Docker service
      ansible.builtin.systemd:
        name: docker
        state: started
        enabled: true
      when: docker_installed.rc != 0

    - name: Add user to docker group
      ansible.builtin.user:
        name: "{{ ansible_user }}"
        groups: docker
        append: true
      when: docker_installed.rc != 0

    - name: Verify Docker installation
      ansible.builtin.command: docker --version
      register: docker_final_version
      changed_when: false

    - name: Display final Docker status
      ansible.builtin.debug:
        msg: "Docker is ready: {{ docker_final_version.stdout }}"

    # ============================================
    # Environment Configuration
    # ============================================
    - name: Check if .env file already exists
      stat:
        path: .env
      register: env_file_exists

    - name: Prompt to use existing .env file
      pause:
        prompt: ".env file already exists. Do you want to use it? (y/n) [y]"
        echo: yes
      register: use_existing_env
      when: env_file_exists.stat.exists

    - name: Load existing .env variables
      shell: cat .env
      register: existing_env
      when: 
        - env_file_exists.stat.exists
        - use_existing_env.user_input | default('y', true) | lower in ['y', 'yes', '']

    - name: Parse existing .env file
      set_fact:
        stack_version: "{{ existing_env.stdout | regex_search('STACK_VERSION=(.+)', '\\1') | first | default('9.2.2', true) }}"
        cluster_name: "{{ existing_env.stdout | regex_search('CLUSTER_NAME=(.+)', '\\1') | first | default('orochi', true) }}"
        license: "{{ existing_env.stdout | regex_search('LICENSE=(.+)', '\\1') | first | default('basic', true) }}"
        mem_limit: "{{ existing_env.stdout | regex_search('MEM_LIMIT=(.+)', '\\1') | first | default('4g', true) }}"
        common_password: "{{ existing_env.stdout | regex_search('ELASTIC_PASSWORD=(.+)', '\\1') | first }}"
        velox_user: "{{ existing_env.stdout | regex_search('VELOX_USER=(.+)', '\\1') | first | default('admin', true) }}"
        velox_role: "{{ existing_env.stdout | regex_search('VELOX_ROLE=(.+)', '\\1') | first | default('administrator', true) }}"
        es_port: "{{ existing_env.stdout | regex_search('ES_PORT=(.+)', '\\1') | first | default('9200', true) }}"
        kibana_port: "{{ existing_env.stdout | regex_search('KIBANA_PORT=(.+)', '\\1') | first | default('5601', true) }}"
        fleet_port: "{{ existing_env.stdout | regex_search('FLEET_PORT=(.+)', '\\1') | first | default('8220', true) }}"
        suricata_port: "{{ existing_env.stdout | regex_search('SURICATA_PORT=(.+)', '\\1') | first | default('8000', true) }}"
        local_kbn_url: "{{ existing_env.stdout | regex_search('LOCAL_KBN_URL=(.+)', '\\1') | first | default('https://0.0.0.0:5601', true) }}"
        suricata_interface: "{{ existing_env.stdout | regex_search('SURICATA_INTERFACE=(.+)', '\\1') | first | default('ens33', true) }}"
        arkime_es_ip: "{{ existing_env.stdout | regex_search('ARKIME_ELASTICSEARCH_IP=(.+)', '\\1') | first | default('127.0.0.1', true) }}"
        velox_server_url: "{{ existing_env.stdout | regex_search('VELOX_SERVER_URL=(.+)', '\\1') | first | default('https://0.0.0.0:8889/', true) }}"
        velox_hostname: "{{ existing_env.stdout | regex_search('VELOX_FRONTEND_HOSTNAME=(.+)', '\\1') | first | default('0.0.0.0', true) }}"
        selected_ip: "{{ existing_env.stdout | regex_search('selected_ip=(.+)', '\\1') | first | default('127.0.0.1', true) }}"
        arkime_password_secret: "{{ existing_env.stdout | regex_search('ARKIME_PASSWORD_SECRET=(.+)', '\\1') | first }}"
        skip_env_prompts: true
      when: 
        - env_file_exists.stat.exists
        - use_existing_env.user_input | default('y', true) | lower in ['y', 'yes', '']

    - name: Display using existing .env
      debug:
        msg: "Using existing .env file configuration"
      when: 
        - env_file_exists.stat.exists
        - use_existing_env.user_input | default('y', true) | lower in ['y', 'yes', '']

    - name: Prompt for Elastic Stack version
      pause:
        prompt: "Enter Elastic Stack version [9.2.2]"
        echo: yes
      register: stack_version_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for cluster name
      pause:
        prompt: "Enter cluster name [orochi]"
        echo: yes
      register: cluster_name_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for license type
      pause:
        prompt: "Enter license type [basic]"
        echo: yes
      register: license_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for memory limit
      pause:
        prompt: "Enter memory limit [4g]"
        echo: yes
      register: mem_limit_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for password (used for all services)
      pause:
        prompt: "Enter a password for all services"
        echo: no
      register: password_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Velociraptor username
      pause:
        prompt: "Enter Velociraptor username [admin]"
        echo: yes
      register: velox_user_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Velociraptor role
      pause:
        prompt: "Enter Velociraptor role [administrator]"
        echo: yes
      register: velox_role_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Elasticsearch port
      pause:
        prompt: "Enter Elasticsearch port [9200]"
        echo: yes
      register: es_port_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Kibana port
      pause:
        prompt: "Enter Kibana port [5601]"
        echo: yes
      register: kibana_port_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Fleet Server port
      pause:
        prompt: "Enter Fleet Server port [8220]"
        echo: yes
      register: fleet_port_input
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Suricata port
      pause:
        prompt: "Enter Suricata port [8000]"
        echo: yes
      register: suricata_port_input
      when: not (skip_env_prompts | default(false))

    - name: Build network interfaces list
      shell: |
        counter=1
        ip -o -4 addr show | while read line; do
          iface=$(echo "$line" | awk '{print $2}')
          ip=$(echo "$line" | awk '{print $4}' | cut -d'/' -f1)
          case "$iface" in
            lo|docker*|br-*|veth*) continue ;;
          esac
          echo "${counter}. ${iface} (${ip})"
          counter=$((counter + 1))
        done
      register: network_interfaces
      changed_when: false
      when: not (skip_env_prompts | default(false))

    - name: Build IP lookup table
      shell: |
        ip -o -4 addr show | while read line; do
          iface=$(echo "$line" | awk '{print $2}')
          ip=$(echo "$line" | awk '{print $4}' | cut -d'/' -f1)
          case "$iface" in
            lo|docker*|br-*|veth*) continue ;;
          esac
          echo "$ip"
        done
      register: ip_lookup_table
      changed_when: false
      when: not (skip_env_prompts | default(false))

    - name: Build interface lookup table
      shell: |
        ip -o -4 addr show | while read line; do
          iface=$(echo "$line" | awk '{print $2}')
          case "$iface" in
            lo|docker*|br-*|veth*) continue ;;
          esac
          echo "$iface"
        done
      register: iface_lookup_table
      changed_when: false
      when: not (skip_env_prompts | default(false))

    - name: Display available network interfaces
      debug:
        msg: "{{ network_interfaces.stdout_lines }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Suricata interface selection
      pause:
        prompt: "Select Suricata interface number or press Enter for [ens33]"
        echo: yes
      register: suricata_interface_input
      when: not (skip_env_prompts | default(false))

    - name: Parse Suricata interface selection
      set_fact:
        suricata_interface_parsed_value: "{{ iface_lookup_table.stdout_lines[suricata_interface_input.user_input | int - 1] if suricata_interface_input.user_input | default('') | regex_search('^[0-9]+$') else suricata_interface_input.user_input | default('ens33', true) }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Arkime Elasticsearch IP
      pause:
        prompt: "Select Arkime Elasticsearch IP number or enter IP manually [127.0.0.1]"
        echo: yes
      register: arkime_es_ip_input
      when: not (skip_env_prompts | default(false))

    - name: Parse Arkime Elasticsearch IP
      set_fact:
        arkime_es_ip_parsed_value: "{{ ip_lookup_table.stdout_lines[arkime_es_ip_input.user_input | int - 1] if arkime_es_ip_input.user_input | default('') | regex_search('^[0-9]+$') else arkime_es_ip_input.user_input | default('127.0.0.1', true) }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Velociraptor server URL
      pause:
        prompt: "Enter Velociraptor server URL [https://0.0.0.0:8889/]"
        echo: yes
      register: velox_url_input
      when: not (skip_env_prompts | default(false))

    - name: Format Velociraptor server URL
      set_fact:
        velox_server_url_new: "{{ velox_url_input.user_input | default('https://0.0.0.0:8889/', true) | regex_replace('^(?!https?://)', 'https://') | regex_replace('(?<!:[0-9]{4})/?$', ':8889/') | regex_replace('(?<![/])$', '/') }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Velociraptor frontend hostname
      pause:
        prompt: "Select Velociraptor frontend hostname number or enter IP"
        echo: yes
      register: velox_hostname_input
      when: not (skip_env_prompts | default(false))

    - name: Parse Velociraptor frontend hostname
      set_fact:
        velox_hostname_parsed_value: "{{ ip_lookup_table.stdout_lines[velox_hostname_input.user_input | int - 1] if velox_hostname_input.user_input | default('') | regex_search('^[0-9]+$') else velox_hostname_input.user_input | default('0.0.0.0', true) }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for Fleet Server host IP
      pause:
        prompt: "Select Fleet Server host IP number or enter IP manually"
        echo: yes
      register: fleet_ip_input
      when: not (skip_env_prompts | default(false))

    - name: Parse Fleet Server IP
      set_fact:
        selected_ip_parsed_value: "{{ ip_lookup_table.stdout_lines[fleet_ip_input.user_input | int - 1] if fleet_ip_input.user_input | default('') | regex_search('^[0-9]+$') else fleet_ip_input.user_input | default('127.0.0.1', true) }}"
      when: not (skip_env_prompts | default(false))

    - name: Prompt for local Kibana URL
      pause:
        prompt: "Enter local Kibana URL [https://0.0.0.0:5601]"
        echo: yes
      register: kibana_url_input
      when: not (skip_env_prompts | default(false))

    - name: Generate Arkime password secret
      shell: openssl rand -base64 32
      register: arkime_password_secret_new
      changed_when: false
      when: not (skip_env_prompts | default(false))

    - name: Set fact variables with defaults (from prompts)
      set_fact:
        stack_version: "{{ stack_version_input.user_input | default('9.2.2', true) }}"
        cluster_name: "{{ cluster_name_input.user_input | default('orochi', true) }}"
        license: "{{ license_input.user_input | default('basic', true) }}"
        mem_limit: "{{ mem_limit_input.user_input | default('4g', true) }}"
        common_password: "{{ password_input.user_input }}"
        velox_user: "{{ velox_user_input.user_input | default('admin', true) }}"
        velox_role: "{{ velox_role_input.user_input | default('administrator', true) }}"
        es_port: "{{ es_port_input.user_input | default('9200', true) }}"
        kibana_port: "{{ kibana_port_input.user_input | default('5601', true) }}"
        fleet_port: "{{ fleet_port_input.user_input | default('8220', true) }}"
        suricata_port: "{{ suricata_port_input.user_input | default('8000', true) }}"
        local_kbn_url: "{{ kibana_url_input.user_input | default('https://0.0.0.0:5601', true) }}"
        suricata_interface: "{{ suricata_interface_parsed_value }}"
        arkime_es_ip: "{{ arkime_es_ip_parsed_value }}"
        velox_server_url: "{{ velox_server_url_new }}"
        velox_hostname: "{{ velox_hostname_parsed_value }}"
        selected_ip: "{{ selected_ip_parsed_value }}"
        arkime_password_secret: "{{ arkime_password_secret_new.stdout }}"
      when: not (skip_env_prompts | default(false))

    - name: Create .env file
      copy:
        content: |
          # Elastic Stack Configuration
          STACK_VERSION={{ stack_version }}
          CLUSTER_NAME={{ cluster_name }}
          LICENSE={{ license }}
          MEM_LIMIT={{ mem_limit }}

          # Passwords (same for all services)
          ELASTIC_PASSWORD={{ common_password }}
          KIBANA_PASSWORD={{ common_password }}
          ARKIME_PASSWORD={{ common_password }}
          VELOX_PASSWORD={{ common_password }}

          # Velociraptor Configuration
          VELOX_USER={{ velox_user }}
          VELOX_ROLE={{ velox_role }}
          VELOX_SERVER_URL={{ velox_server_url }}
          VELOX_FRONTEND_HOSTNAME={{ velox_hostname }}

          # Network Configuration
          ES_PORT={{ es_port }}
          KIBANA_PORT={{ kibana_port }}
          FLEET_PORT={{ fleet_port }}
          SURICATA_PORT={{ suricata_port }}
          SURICATA_INTERFACE={{ suricata_interface }}

          # Arkime Configuration
          ARKIME_ELASTICSEARCH_IP={{ arkime_es_ip }}
          ARKIME_PASSWORD_SECRET={{ arkime_password_secret }}

          # Fleet Configuration
          FLEET_SERVER_HOST={{ selected_ip }}
          selected_ip={{ selected_ip }}
          LOCAL_KBN_URL=https://{{ selected_ip }}:{{ kibana_port }}

          # Default Settings
          DEFAULT_TIMEOUT=300
        dest: .env
        mode: '0600'

    - name: Display .env file creation success
      debug:
        msg: ".env file created/updated successfully!"

    # ============================================
    # Pull Docker Images
    # ============================================
    - name: Define required Docker images
      set_fact:
        docker_images:
          - "docker.elastic.co/elasticsearch/elasticsearch:{{ stack_version }}"
          - "docker.elastic.co/kibana/kibana:{{ stack_version }}"
          - "docker.elastic.co/logstash/logstash:{{ stack_version }}"
          - "thehiveproject/thehive4:4.1.19"
          - "docker.elastic.co/elasticsearch/elasticsearch:7.17.9"
          - "cassandra:4.0"
          - "mattermost/mattermost-team-edition:latest"
          - "postgres:15-alpine"
          - "mongo:4.4"
          - "jasonish/suricata:latest"
          - "mammo0/docker-arkime:latest"
          - "ghcr.io/gchq/cyberchef:latest"
          - "nginx:alpine"

    - name: Pull Docker images
      community.docker.docker_image:
        name: "{{ item }}"
        source: pull
      loop: "{{ docker_images }}"
      register: pull_result
      ignore_errors: true

    - name: Display pull summary
      debug:
        msg: "Docker image pull complete"

    # ============================================
    # Elasticsearch Setup
    # ============================================
    - name: Create Elasticsearch directories
      file:
        path: "{{ item }}"
        state: directory
        mode: '0777'
        owner: 1000
        group: 1000
      loop:
        - /opt/orochi/certs
        - /opt/orochi/esdata
        - /opt/orochi/data
        - /opt/orochi/logs

    - name: Check if Elasticsearch certificates exist
      stat:
        path: /opt/orochi/certs/ca/ca.crt
      register: certs_exist

    - name: Generate Elasticsearch certificates
      shell: |
        docker run --rm --user root \
          -v /opt/orochi/certs:/usr/share/elasticsearch/config/certs \
          docker.elastic.co/elasticsearch/elasticsearch:{{ stack_version }} \
          bash -c '
            cd /usr/share/elasticsearch
            bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip
            cd config/certs && unzip -o ca.zip
            cd /usr/share/elasticsearch
            bin/elasticsearch-certutil cert --silent --pem \
              -out config/certs/certs.zip \
              --ca-cert config/certs/ca/ca.crt \
              --ca-key config/certs/ca/ca.key \
              --name elasticsearch \
              --dns elasticsearch --dns kibana --dns fleet-server --dns localhost \
              --ip 127.0.0.1 --ip {{ selected_ip }}
            cd config/certs && unzip -o certs.zip
            chmod -R 755 /usr/share/elasticsearch/config/certs
          '
      when: not certs_exist.stat.exists

    - name: Fix certificate permissions
      file:
        path: /opt/orochi/certs
        state: directory
        recurse: yes
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Create Docker network
      community.docker.docker_network:
        name: orochi-network
        state: present
    
    - name: Start Elasticsearch container
      community.docker.docker_container:
        name: elasticsearch
        image: "docker.elastic.co/elasticsearch/elasticsearch:{{ stack_version }}"
        state: started
        restart_policy: unless-stopped
        hostname: elasticsearch
        networks:
          - name: orochi-network
        ports:
          - "{{ es_port }}:9200"
        volumes:
          - /opt/orochi/certs:/usr/share/elasticsearch/config/certs:ro
          - /opt/orochi/esdata:/usr/share/elasticsearch/data
        env:
          node.name: elasticsearch
          cluster.name: "{{ cluster_name }}"
          discovery.type: single-node
          ELASTIC_PASSWORD: "{{ common_password }}"
          bootstrap.memory_lock: "true"
          xpack.security.enabled: "true"
          xpack.security.http.ssl.enabled: "true"
          xpack.security.http.ssl.key: certs/elasticsearch/elasticsearch.key
          xpack.security.http.ssl.certificate: certs/elasticsearch/elasticsearch.crt
          xpack.security.http.ssl.certificate_authorities: certs/ca/ca.crt
          xpack.security.transport.ssl.enabled: "true"
          xpack.security.transport.ssl.key: certs/elasticsearch/elasticsearch.key
          xpack.security.transport.ssl.certificate: certs/elasticsearch/elasticsearch.crt
          xpack.security.transport.ssl.certificate_authorities: certs/ca/ca.crt
          xpack.security.transport.ssl.verification_mode: certificate
          xpack.license.self_generated.type: "{{ license }}"
        ulimits:
          - memlock:-1:-1
        memory: "{{ mem_limit }}"

    - name: Wait for Elasticsearch to be ready
      uri:
        url: "https://localhost:{{ es_port }}/_cluster/health"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        validate_certs: no
        status_code: 200
      register: es_health
      until: es_health.status == 200
      retries: 30
      delay: 10

    # FIXED: Proper cluster configuration without breaking data streams
    - name: Configure cluster settings for single-node
      uri:
        url: "https://localhost:{{ es_port }}/_cluster/settings"
        method: PUT
        user: elastic
        password: "{{ common_password }}"
        body_format: json
        body:
          persistent:
            action:
              auto_create_index: "true"
        validate_certs: no
        status_code: [200]
      ignore_errors: yes

    - name: Display Elasticsearch status
      debug:
        msg: 
          - "Elasticsearch is running at https://localhost:{{ es_port }}"
          - "Cluster: {{ cluster_name }}"
          - "Version: {{ stack_version }}"
          - "Single-node configuration applied"

    # ============================================
    # Kibana Setup
    # ============================================
    - name: Create Kibana data directory
      file:
        path: /opt/orochi/kibanadata
        state: directory
        mode: '0777'
        owner: 1000
        group: 1000

    - name: Set kibana_system user password
      uri:
        url: "https://localhost:{{ es_port }}/_security/user/kibana_system/_password"
        method: POST
        user: elastic
        password: "{{ common_password }}"
        body_format: json
        body:
          password: "{{ common_password }}"
        validate_certs: no
        status_code: 200

    - name: Start Kibana container
      community.docker.docker_container:
        name: kibana
        image: "docker.elastic.co/kibana/kibana:{{ stack_version }}"
        state: started
        restart_policy: unless-stopped
        networks:
          - name: orochi-network
        ports:
          - "{{ kibana_port }}:5601"
        volumes:
          - /opt/orochi/certs:/usr/share/kibana/config/certs:ro
          - /opt/orochi/kibanadata:/usr/share/kibana/data
        env:
          SERVERNAME: kibana
          ELASTICSEARCH_HOSTS: "https://elasticsearch:9200"
          ELASTICSEARCH_USERNAME: kibana_system
          ELASTICSEARCH_PASSWORD: "{{ common_password }}"
          ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: config/certs/ca/ca.crt
          SERVER_SSL_ENABLED: "true"
          SERVER_SSL_CERTIFICATE: config/certs/elasticsearch/elasticsearch.crt
          SERVER_SSL_KEY: config/certs/elasticsearch/elasticsearch.key
          XPACK_SECURITY_ENCRYPTIONKEY: "fhjskloppd678ehkdfdlliverpoolfcr"
          XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: "fhjskloppd678ehkdfdlliverpoolfcr"
          hostname: kibana
        memory: "{{ mem_limit }}"

    - name: Wait for Kibana to be ready
      uri:
        url: "https://localhost:{{ kibana_port }}/api/status"
        method: GET
        validate_certs: no
        status_code: 200
      register: kibana_status
      until: kibana_status.status == 200
      retries: 60
      delay: 10

    - name: Display Kibana status
      debug:
        msg:
          - "Kibana is running at https://localhost:{{ kibana_port }}"
          - "Username: elastic"
          - "Password: (as configured)"


# ============================================
    # Install and Configure Fleet Server
    # ============================================
    - name: Create Fleet Server data directory
      file:
        path: /opt/orochi/fleetserverdata
        state: directory
        mode: '0777'
        owner: 1000
        group: 1000

    - name: Get Elasticsearch CA fingerprint
      shell: |
        openssl x509 -fingerprint -sha256 -noout -in /opt/orochi/certs/ca/ca.crt | cut -d= -f2 | tr -d :
      register: ca_fingerprint
      changed_when: false
    - name: Start Fleet Server container
      community.docker.docker_container:
        name: fleet-server
        image: "docker.elastic.co/elastic-agent/elastic-agent:{{ stack_version }}"
        state: started
        restart_policy: unless-stopped
        user: root
        networks:
          - name: orochi-network
        ports:
          - "{{ fleet_port }}:8220"
        volumes:
          - /opt/orochi/certs:/certs:ro
          - /opt/orochi/fleetserverdata:/usr/share/elastic-agent/state
          - /var/lib/docker/containers:/var/lib/docker/containers:ro
          - /var/run/docker.sock:/var/run/docker.sock:ro
          - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
          - /proc:/hostfs/proc:ro
          - /:/hostfs:ro
        hostname: fleet-server
        env:
          CERTIFICATE_AUTHORITIES: /certs/ca/ca.crt
          FLEET_CA: /certs/ca/ca.crt
          FLEET_ENROLL: "1"
          FLEET_SERVER_ELASTICSEARCH_CA: /certs/ca/ca.crt
          FLEET_SERVER_ELASTICSEARCH_HOST: "https://elasticsearch:9200"
          FLEET_SERVER_ELASTICSEARCH_USERNAME: "elastic"
          FLEET_SERVER_ELASTICSEARCH_PASSWORD: "{{ common_password }}"
          FLEET_SERVER_ENABLE: "1"
          FLEET_SERVER_CERT: /certs/elasticsearch/elasticsearch.crt
          FLEET_SERVER_CERT_KEY: /certs/elasticsearch/elasticsearch.key
          FLEET_SERVER_POLICY_ID: fleet-server-policy
          FLEET_URL: "https://fleet-server:8220"
          KIBANA_FLEET_CA: /certs/ca/ca.crt
          KIBANA_FLEET_SETUP: "1"
          KIBANA_FLEET_USERNAME: elastic
          KIBANA_FLEET_PASSWORD: "{{ common_password }}"
          KIBANA_HOST: "https://kibana:5601"

    - name: Wait for Fleet Server port to be available
      wait_for:
        host: localhost
        port: "{{ fleet_port }}"
        delay: 10
        timeout: 120

    - name: Wait for Kibana Fleet API to be ready
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/agents/setup"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: fleet_api_ready
      until: fleet_api_ready.status == 200
      retries: 30
      delay: 10

    # ============================================
    # Create Fleet Server Policy
    # ============================================
    - name: Check if fleet-server-policy exists
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/agent_policies/fleet-server-policy"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200, 404]
      register: fleet_policy_check

    - name: Create Fleet Server policy
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/agent_policies"
        method: POST
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          id: "fleet-server-policy"
          name: "Fleet Server Policy"
          namespace: "default"
          monitoring_enabled:
            - logs
            - metrics
          has_fleet_server: true
        validate_certs: no
        status_code: [200, 201]
      when: fleet_policy_check.status == 404
      register: fleet_policy_created

    # ============================================
    # Get Fleet Server package version and add integration
    # ============================================
    - name: Get fleet_server package info
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/epm/packages/fleet_server"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: fleet_server_package

    - name: Set fleet_server package version
      set_fact:
        fleet_server_version: "{{ fleet_server_package.json.item.version }}"

    - name: Debug fleet_server package version
      debug:
        msg: "Fleet Server package version: {{ fleet_server_version }}"

    - name: Get all package policies
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/package_policies"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: all_package_policies

    - name: Extract package policies list
      set_fact:
        package_policies_list: "{{ all_package_policies.json['items'] | default([]) }}"

    - name: Check if Fleet Server integration exists
      set_fact:
        fleet_server_integration_exists: false

    - name: Set integration exists if found
      set_fact:
        fleet_server_integration_exists: true
      loop: "{{ package_policies_list }}"
      loop_control:
        loop_var: policy_item
      when: 
        - policy_item.policy_id is defined
        - policy_item.policy_id == 'fleet-server-policy'
        - policy_item.package is defined
        - policy_item.package.name is defined
        - policy_item.package.name == 'fleet_server'

    - name: Debug integration check result
      debug:
        msg: "Fleet Server integration exists: {{ fleet_server_integration_exists }}"

    - name: Add Fleet Server integration to policy
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/package_policies"
        method: POST
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          name: "fleet-server-integration"
          namespace: "default"
          policy_id: "fleet-server-policy"
          enabled: true
          inputs:
            - type: "fleet-server"
              enabled: true
              streams: []
              vars:
                host:
                  value: "0.0.0.0"
                  type: "text"
                port:
                  value: 8220
                  type: "integer"
          package:
            name: "fleet_server"
            version: "{{ fleet_server_version }}"
        validate_certs: no
        status_code: [200, 201]
      when: not fleet_server_integration_exists
      register: fleet_integration_added

    # ============================================
    # Configure Fleet Server hosts and outputs
    # ============================================
    - name: Get existing Fleet Server hosts
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/fleet_server_hosts"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: fleet_server_hosts

    - name: Create Fleet Server host configuration
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/fleet_server_hosts"
        method: POST
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          name: "Default Fleet Server"
          host_urls:
            - "https://{{ selected_ip }}:{{ fleet_port }}"
          is_default: true
        validate_certs: no
        status_code: [200, 201]
      when: fleet_server_hosts.json.total == 0
      register: create_fleet_host

    - name: Get first Fleet Server host ID
      set_fact:
        fleet_server_host_id: "{{ fleet_server_hosts.json['items'][0].id }}"
      when: fleet_server_hosts.json.total > 0

    - name: Update existing Fleet Server host
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/fleet_server_hosts/{{ fleet_server_host_id }}"
        method: PUT
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          host_urls:
            - "https://{{ selected_ip }}:{{ fleet_port }}"
        validate_certs: no
        status_code: [200]
      when: fleet_server_host_id is defined

    - name: Get existing outputs
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/outputs"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: fleet_outputs

    - name: Get default output ID
      set_fact:
        default_output_id: "{{ fleet_outputs.json['items'][0].id }}"
      when: fleet_outputs.json.total > 0

    - name: Update Fleet default output
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/outputs/{{ default_output_id }}"
        method: PUT
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          hosts:
            - "https://{{ selected_ip }}:{{ es_port }}"
          ca_trusted_fingerprint: "{{ ca_fingerprint.stdout }}"
        validate_certs: no
        status_code: [200]
      when: default_output_id is defined
    - name: Read CA certificate content
      slurp:
        src: /opt/orochi/certs/ca/ca.crt
      register: ca_cert_content

    - name: Update Fleet output with CA certificate
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/outputs/{{ default_output_id }}"
        method: PUT
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
          Content-Type: "application/json"
        body_format: json
        body:
          hosts:
            - "https://{{ selected_ip }}:{{ es_port }}"
          ca_trusted_fingerprint: "{{ ca_fingerprint.stdout }}"
          ssl:
            certificate_authorities:
              - "{{ ca_cert_content.content | b64decode }}"
        validate_certs: no
        status_code: [200]
      when: default_output_id is defined

    # ============================================
    # Wait for Fleet Server to become healthy
    # ============================================
    - name: Clear Fleet Server state for fresh enrollment
      shell: |
        docker stop fleet-server
        rm -rf /opt/orochi/fleetserverdata/*
        docker start fleet-server
      when: fleet_integration_added is changed

    - name: Wait for Fleet Server to restart
      wait_for:
        host: localhost
        port: "{{ fleet_port }}"
        delay: 10
        timeout: 120
      when: fleet_integration_added is changed

    - name: Wait for Fleet Server to become healthy
      uri:
        url: "https://localhost:{{ fleet_port }}/api/status"
        method: GET
        validate_certs: no
        status_code: [200]
      register: fleet_server_status
      #until: fleet_server_status.json.status == "HEALTHY"
      until: 
        - fleet_server_status.status is defined
        - fleet_server_status.status == 200
        - fleet_server_status.json is defined
        - fleet_server_status.json.status is defined
        - fleet_server_status.json.status == "HEALTHY"      
      retries: 30
      delay: 10
      ignore_errors: yes

    - name: Get Fleet agents
      uri:
        url: "https://localhost:{{ kibana_port }}/api/fleet/agents"
        method: GET
        user: elastic
        password: "{{ common_password }}"
        force_basic_auth: yes
        headers:
          kbn-xsrf: "true"
        validate_certs: no
        status_code: [200]
      register: fleet_agents
      retries: 6
      delay: 10
      until: fleet_agents.json.total > 0
      ignore_errors: yes

    # ============================================
    # Display summary
    # ============================================
    - name: Display Fleet Server configuration summary
      debug:
        msg:
          - "=========================================="
          - "Fleet Server Status"
          - "=========================================="
          - "Fleet Server URL: https://{{ selected_ip }}:{{ fleet_port }}"
          - "Fleet Server Package Version: {{ fleet_server_version }}"
          - "Fleet Server Status: {{ fleet_server_status.json.status | default('Check logs') }}"
          - "Fleet Agents Enrolled: {{ fleet_agents.json.total | default('0') }}"
          - "Elasticsearch Output: https://{{ selected_ip }}:{{ es_port }}"
          - "CA Fingerprint: {{ ca_fingerprint.stdout }}"
          - "=========================================="
          - "Access Kibana Fleet UI:"
          - "https://{{ selected_ip }}:{{ kibana_port }}/app/fleet"
          - "=========================================="

    # ============================================
    # THEHIVE 4 STACK (Refactored from Project Tiamat)
    # ============================================

    # 1. Create Data Directories
    - name: Create TheHive directories
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000
      loop:
        - /opt/orochi/hive_data
        - /opt/orochi/hive_es_data
        - /opt/orochi/cassandra_data
        - /opt/orochi/hive_conf

    # 2. Elasticsearch 7 (Required for TheHive 4)
    # Tiamat used ES 7.9.2, we are using 7.17.9 (More stable)
    - name: Start Elasticsearch 7
      community.docker.docker_container:
        name: elasticsearch-hive
        image: "docker.elastic.co/elasticsearch/elasticsearch:7.17.9"
        state: started
        restart_policy: unless-stopped
        networks:
          - name: orochi-network
        env:
          discovery.type: "single-node"
          xpack.security.enabled: "false"
          cluster.name: "hive"
          "ES_JAVA_OPTS": "-Xms512m -Xmx512m"
        volumes:
          - /opt/orochi/hive_es_data:/usr/share/elasticsearch/data
        memory: "1g"

    # --- 2. Cassandra (The Data Store) ---
    - name: Start Cassandra
      community.docker.docker_container:
        name: cassandra
        image: "cassandra:4.0"
        state: started
        restart_policy: unless-stopped
        networks:
          - name: orochi-network
        volumes:
          - /opt/orochi/cassandra_data:/var/lib/cassandra
        env:
          CASSANDRA_CLUSTER_NAME: "TheHive"
          # TAME THE BEAST: Force Java to use less RAM
          MAX_HEAP_SIZE: "1024M" 
          HEAP_NEWSIZE: "256M"
        # Increase container limit slightly to allow for overhead + Heap
        memory: "2g" 
        healthcheck:
          test: ["CMD-SHELL", "[ $$(nodetool statusgossip) = running ] || exit 1"]
          interval: 30s
          timeout: 10s
          retries: 5

    # 4. Generate TheHive Config (Replaces Tiamat's application.conf injection)
    - name: Generate Hive Secret
      shell: cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1
      register: hive_secret
      changed_when: false

    - name: Create TheHive application.conf
      copy:
        dest: /opt/orochi/hive_conf/application.conf
        content: |
          play.http.secret.key="{{ hive_secret.stdout }}"
          
          # Database (Cassandra)
          db.janusgraph {
            storage {
              backend: cql
              hostname: ["cassandra"]
              cql {
                cluster-name: TheHive
                keyspace: thehive
              }
            }
            index {
              search {
                backend: elasticsearch
                hostname: ["elasticsearch-hive"]
                index-name: thehive
              }
            }
          }
          
          # Storage (Local files)
          storage {
            provider: localfs
            localfs.directory: /opt/thp/thehive/files
          }
        mode: '0644'

    # 5. Wait for Cassandra (It's slower than Mongo)
    - name: Wait for Cassandra to initialize
      pause:
        seconds: 45

    # 6. TheHive 4 Container
    - name: Start TheHive 4
      community.docker.docker_container:
        name: thehive
        image: "thehiveproject/thehive4:4.1.19"
        state: started
        restart_policy: unless-stopped
        networks:
          - name: orochi-network
        ports:
          - "9000:9000"
        volumes:
          - /opt/orochi/hive_conf/application.conf:/etc/thehive/application.conf
          - /opt/orochi/hive_data:/opt/thp/thehive/files
        memory: "2g"

    - name: Display TheHive Status
      debug:
        msg: "TheHive is running at http://{{ selected_ip }}:9000 (User: admin / Pass: admin)"

    # ============================================
    # VELOCIRAPTOR (Digital Forensics & IR)
    # ============================================

    - name: Create Velociraptor build directory
      file:
        path: /opt/orochi/velociraptor-build
        state: directory
        mode: '0755'

    - name: Create Velociraptor Dockerfile
      copy:
        dest: /opt/orochi/velociraptor-build/Dockerfile
        content: |
          FROM debian:bookworm-slim

          # Install curl to query GitHub
          RUN apt-get update && apt-get install -y \
              curl \
              ca-certificates \
              && rm -rf /var/lib/apt/lists/*
          RUN URL=$(curl -s https://api.github.com/repos/Velocidex/velociraptor/releases/latest \
                | grep "browser_download_url.*linux-amd64\"" \
                | grep -v "musl" \
                | grep -v "sig" \
                | tail -n 1 \
                | cut -d '"' -f 4) \
              && echo "Downloading: $URL" \
              && curl -L -o /usr/local/bin/velociraptor "$URL" \
              && chmod +x /usr/local/bin/velociraptor

          RUN mkdir -p /data
          WORKDIR /data
          EXPOSE 8000 8001 8889

          ENTRYPOINT ["/usr/local/bin/velociraptor"]
        mode: '0644'

    - name: Build Velociraptor image
      community.docker.docker_image:
        name: orochi/velociraptor
        tag: latest
        source: build
        build:
          path: /opt/orochi/velociraptor-build
        state: present
        force_source: yes
    
    - name: Create Velociraptor data directory
      file:
        path: /opt/orochi/velociraptor
        state: directory
        mode: '0755'

    - name: Check if Velociraptor config exists
      stat:
        path: /opt/orochi/velociraptor/server.config.yaml
      register: velox_config

    # 3. Generate Configs (The Reliable Merge Method)
    - name: Generate Velociraptor Configuration
      when: not velox_config.stat.exists
      block:
        - name: Create Velociraptor Merge Config
          copy:
            dest: /opt/orochi/velociraptor/merge.json
            content: |
              {
                "Client": {
                  "server_urls": ["https://{{ selected_ip }}:8000/"],
                  "use_self_signed_ssl": true
                },
                "API": {
                  "bind_address": "0.0.0.0",
                  "bind_port": 8001
                },
                "GUI": {
                  "bind_address": "0.0.0.0",
                  "bind_port": 8889,
                  "public_url": "https://{{ selected_ip }}:8889/app/index.html"
                },
                "Frontend": {
                  "bind_address": "0.0.0.0",
                  "bind_port": 8000
                }
              }

        - name: Generate Server Config
          shell: |
            docker run --rm \
              -v /opt/orochi/velociraptor:/data \
              orochi/velociraptor:latest \
              config generate --merge_file /data/merge.json \
              > /opt/orochi/velociraptor/server.config.yaml

        # 3. Generate Client Config
        - name: Generate Client Config
          shell: |
            docker run --rm \
              -v /opt/orochi/velociraptor:/data \
              orochi/velociraptor:latest \
              config client -c /data/server.config.yaml \
              > /opt/orochi/velociraptor/client.config.yaml

        # 4. Clean up the temporary merge file
        - name: Remove merge file
          file:
            path: /opt/orochi/velociraptor/merge.json
            state: absent

    - name: Start Velociraptor
      community.docker.docker_container:
        name: velociraptor
        image: "orochi/velociraptor:latest"
        state: started
        restart_policy: unless-stopped
        networks:
          - name: orochi-network
        ports:
          - "8889:8889"
          - "8000:8000"
          - "8001:8001"
        volumes:
          - /opt/orochi/velociraptor:/data
        command:
          - "frontend"
          - "-v"
          - "--config"
          - "/data/server.config.yaml"

    - name: Wait for Velociraptor to start
      pause:
        seconds: 10

    - name: Create/Update Velociraptor Admin User
      shell: |
        docker exec velociraptor \
          velociraptor --config /data/server.config.yaml \
          user add --role administrator '{{ velox_user }}' '{{ common_password }}'
      changed_when: false
      retries: 3
      delay: 5

    - name: Display Velociraptor Info
      debug:
        msg: "Velociraptor GUI: https://{{ selected_ip }}:8889 (User: {{ velox_user }} / Pass: {{ common_password }})"